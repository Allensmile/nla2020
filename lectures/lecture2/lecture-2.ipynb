{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     1
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 2. Matrix norms and unitary matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of the previous lecture\n",
    "\n",
    "- Floating point  (double, single, half precisions, number of bytes), rounding error\n",
    "- Vector norms are measures of smallness, used to compute the distance and accuracy\n",
    "- Forward/backward error (and stability of algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notations\n",
    "\n",
    "We use notation \n",
    "\n",
    "$$A= \\begin{bmatrix} a_{11} & \\dots & a_{1m} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{n1} & \\dots & a_{nm}  \\end{bmatrix} \\equiv \\{a_{ij}\\}_{i,j=1}^{n,m}\\in \\mathbb{C}^{n\\times m}.$$\n",
    "\n",
    "$A^*\\stackrel{\\mathrm{def}}{=}\\overline{A^\\top}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrices and norms\n",
    "\n",
    "- Recall vector norms that allow to evaluate distance between two vectors or how large are elements of a vector.\n",
    "\n",
    "- How to generalize this concept to matrices?\n",
    "\n",
    "- A trivial answer is that there is no big difference between matrices and vectors, and here comes the simplest matrix norm –– **Frobenius** norm:\n",
    "\n",
    "$$ \\Vert A \\Vert_F \\stackrel{\\mathrm{def}}{=} \\Big(\\sum_{i=1}^n \\sum_{j=1}^m |a_{ij}|^2\\Big)^{1/2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix norms\n",
    "$\\Vert \\cdot \\Vert$ is called a **matrix norm** if it is a vector norm on the vector space of $n \\times m$ matrices:\n",
    "1. $\\|A\\| \\geq 0$ and if $\\|A\\| = 0$ then $A = O$\n",
    "3. $\\|\\alpha A\\| = |\\alpha| \\|A\\|$\n",
    "4. $\\|A+B\\| \\leq \\|A\\| + \\|B\\|$ (triangle inequality)\n",
    "\n",
    "Additionally some norms can satisfy the *submultiplicative property*\n",
    "\n",
    "* <font color='red'> $\\Vert A B \\Vert \\leq \\Vert A \\Vert \\Vert B \\Vert$ </font>\n",
    "\n",
    "- These norms are called **submultiplicative norms**.\n",
    "\n",
    "- The submultiplicative property is needed in many places, for example in the estimates for the error of solution of linear systems (we will cover this topic later). \n",
    "\n",
    "- Example of a non-submultiplicative norm is Chebyshev norm \n",
    "\n",
    "$$ \\|A\\|_C = \\displaystyle{\\max_{i,j}}\\, |a_{ij}| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operator norms\n",
    "\n",
    "- The most important class of the matrix norms is the class of **operator norms**. They are defined as\n",
    "\n",
    "$$ \\Vert A \\Vert_{*,**} = \\sup_{x \\ne 0} \\frac{\\Vert A x \\Vert_*}{\\Vert x \\Vert_{**}}, $$\n",
    "\n",
    "where $\\Vert \\cdot \\Vert_*$ and $\\| \\cdot \\|_{**}$ are **vector norms**.\n",
    "\n",
    "- It is easy to check that operator norms are submultiplicative if $\\|\\cdot\\|_* = \\|\\cdot\\|_{**}$. Otherwise, it can be non-submultiplicative, think about example.\n",
    "\n",
    "- **Frobenius norm** is a matrix norm, but not an operator norm, i.e. you can not find $\\Vert \\cdot \\Vert_*$ and $\\| \\cdot \\|_{**}$ that induce it. \n",
    "- This is a nontrivial fact and the general criterion for matrix norm to be an operator norm can be found in [Theorem 6 and Corollary 4](http://www.sciencedirect.com/science/article/pii/S0024379515004346).\n",
    "For $\\Vert \\cdot \\Vert_* = \\| \\cdot \\|_{**}$ let us check on the blackboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix $p$-norms\n",
    "\n",
    "Important case of operator norms are matrix $p$-norms, which are defined for $\\|\\cdot\\|_* = \\|\\cdot\\|_{**} = \\|\\cdot\\|_p$. <br>\n",
    "\n",
    "Among all $p$-norms three norms are the most common ones:  \n",
    "\n",
    "- $p = 1, \\quad \\Vert A \\Vert_{1} = \\displaystyle{\\max_j \\sum_{i=1}^n} |a_{ij}|$.\n",
    "\n",
    "- $p = 2, \\quad$ spectral norm, denoted by $\\Vert A \\Vert_2$.\n",
    "\n",
    "- $p = \\infty, \\quad \\Vert A \\Vert_{\\infty} = \\displaystyle{\\max_i \\sum_{j=1}^m} |a_{ij}|$.\n",
    "\n",
    "Let us check it for $p=\\infty$ on a blackboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spectral norm\n",
    "\n",
    "- Spectral norm, $\\Vert A \\Vert_2$ is one of the most used matrix norms (along with the Frobenius norm). \n",
    "- It can not be computed directly from the entries using a simple formula, like the Frobenius norm, however, there are efficient algorithms to compute it.  \n",
    "- It is directly related to the **singular value decomposition** (SVD) of the matrix. It holds\n",
    "\n",
    "$$ \\Vert A \\Vert_2 = \\sigma_1(A) = \\sqrt{\\lambda_\\max(A^*A)} $$\n",
    "\n",
    "where $\\sigma_1(A)$ is the largest singular value of the matrix $A$ and $^*$ is a *conjugate transpose* of the matrix. \n",
    "\n",
    "- We will soon learn all about the SVD. Meanwhile, we can already compute the norm in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda3/envs/pytorch/lib/python3.6/site-packages/jax/lib/xla_bridge.py:122: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral: 54.2968864440918 \n",
      "Frobenius: 447.29681396484375 \n",
      "1-norm: 109.0810317993164 \n",
      "infinity: 1655.156005859375\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "n = 100\n",
    "m = 2000\n",
    "a = jax.random.normal(jax.random.PRNGKey(0), (n, m)) #Random n x m matrix\n",
    "s1 = jnp.linalg.norm(a, 2) #Spectral\n",
    "s2 = jnp.linalg.norm(a, 'fro') #Frobenius\n",
    "s3 = jnp.linalg.norm(a, 1) #1-norm\n",
    "s4 = jnp.linalg.norm(a, jnp.inf) \n",
    "print('Spectral: {0:} \\nFrobenius: {1:} \\n1-norm: {2:} \\ninfinity: {3:}'.format(s1, s2, s3, s4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples\n",
    "\n",
    "Several examples of optimization problems where matrix norms arise:\n",
    "* <font color='red'> $\\displaystyle{\\min_{\\mathrm{rank}(A_r)=r}}\\| A - A_r\\|$ </font> –– finding best rank-r approximation. SVD helps to solve this problem for $\\|\\cdot\\|_2$ and $\\|\\cdot\\|_F$.\n",
    "\n",
    "\n",
    "* $\\displaystyle{\\min_B}\\| P_\\Omega \\odot(A - B)\\| + \\mathrm{rank}(B)$ –– matrix completion. \n",
    "\n",
    "$$ (P_\\Omega)_{ij} = \\begin{cases} 1 & i,j\\in\\Omega \\\\ 0 & \\text{otherwise}, \\end{cases} $$\n",
    "\n",
    "where $\\odot$ denotes Hadamard product (elementwise)\n",
    "\n",
    "\n",
    "* $\\displaystyle{\\min_{B,C\\geq 0}} \\|A - BC\\|_F$ –– nonnegative matrix factorization. Symbol $B\\geq0$ here means that all elements of $B$ are nonnegative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scalar product\n",
    "While norm is a measure of distance, the **scalar product** takes angle into account.  \n",
    "\n",
    "It is defined as\n",
    "\n",
    "* **For vectors:**\n",
    "$$ (x, y) =  x^* y = \\sum_{i=1}^n \\overline{x}_i y_i, $$\n",
    "where $\\overline{x}$ denotes the *complex conjugate* of $x$. The Euclidean norm is then\n",
    "\n",
    "$$ \\Vert x \\Vert_2 = \\sqrt{(x, x)}, $$\n",
    "\n",
    "or it is said the norm is **induced** by the scalar product.  \n",
    "\n",
    "\n",
    "* **For matrices** (Frobenius scalar product):\n",
    "\n",
    "$$ (A, B)_F = \\displaystyle{\\sum_{i=1}^{n}\\sum_{j=1}^{m}} \\overline{a}_{ij} b_{ij} \\equiv \\mathrm{trace}(A^* B), $$\n",
    "\n",
    "where $\\mathrm{trace}(A)$ denotes the sum of diagonal elements of $A$. One can check that $\\|A\\|_F = \\sqrt{(A, A)_F}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Remark**. The angle between two vectors is defined as\n",
    "\n",
    "$$ \\cos \\phi = \\frac{(x, y)}{\\Vert x \\Vert_2 \\Vert y \\Vert_2}. $$\n",
    "\n",
    "Similar expression holds for matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- An important property of the scalar product is the **Cauchy-Schwarz-Bunyakovski inequality**:\n",
    "\n",
    "$$|(x, y)| \\leq \\Vert x \\Vert_2 \\Vert y \\Vert_2,$$\n",
    "\n",
    "and thus the angle between two vectors is defined properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrices preserving the norm\n",
    "\n",
    "- For stability it is really important that the error does not grow after we apply some transformations. \n",
    "\n",
    "- Suppose you are given $\\widehat{x}$ –– the approximation of $x$ such that,  \n",
    "\n",
    "$$ \\frac{\\Vert x - \\widehat{x} \\Vert}{\\Vert x \\Vert} \\leq \\varepsilon. $$\n",
    "\n",
    "- Let us calculate a linear transformation of $x$ and $\\widehat{x}$:  \n",
    "\n",
    "$$ y = U x, \\quad \\widehat{y} = U \\widehat{x}. $$\n",
    "\n",
    "- When building new algorithms, we want to use transformations that do not increase (or even preserve) the error:\n",
    "\n",
    "$$ \\frac{\\Vert y - \\widehat{y} \\Vert}{\\Vert y \\Vert } = \\frac{\\Vert U ( x - \\widehat{x}) \\Vert}{\\Vert U  x\\Vert}  \\leq \\varepsilon. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The question is for which kind of matrices the norm of the vector **will not change**, so that\n",
    "\n",
    "$$ \\frac{\\Vert U ( x - \\widehat{x}) \\Vert}{\\Vert U  x\\Vert} = \\frac{ \\|x - \\widehat{x}\\|}{\\|x\\|}. $$\n",
    "\n",
    "- For the euclidean norm $\\|\\cdot\\|_2$ the answer is **unitary** (or orthogonal in the real case) matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unitary (orthogonal) matrices\n",
    "\n",
    "- Let $U$ be complex $n \\times n$ matrix, and $\\Vert U z \\Vert_2 = \\Vert z \\Vert_2$ for all $z$. \n",
    "\n",
    "- This can happen **if and only if** (can be abbreviated as **iff**)\n",
    "\n",
    "$$ U^* U = I_n, $$\n",
    "\n",
    "where $I_n$ is an identity matrix $n\\times n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Complex $n\\times n$ square matrix is called **unitary** if\n",
    "\n",
    "$$ U^*U = UU^* = I_n, $$\n",
    "\n",
    "which means that columns and rows of unitary matrices both form orthonormal basis in $\\mathbb{C}^{n}$.\n",
    "\n",
    "- For rectangular matrices of size $m\\times n$ ($n\\not= m$) only one of the equalities can hold\n",
    "\n",
    "    - $ U^*U = I_n$ –– left unitary for $m>n$\n",
    "    - $ UU^* = I_m$  –– right unitary for $m<n$\n",
    "\n",
    "- In the case of real matrices $U^* = U^T$ and matrices such that\n",
    "\n",
    "$$ U^TU = UU^T = I $$\n",
    "\n",
    "are called **orthogonal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unitary matrices\n",
    "\n",
    "Important property: **a product of two unitary matrices is a unitary matrix:**  \n",
    "\n",
    "$$(UV)^* UV = V^* (U^* U) V = V^* V = I,$$\n",
    "\n",
    "- Later we will show that there are types of matrices (**Householder reflections** and **Givens rotations**) composition of which is able to produce arbitrary unitary matrix\n",
    "- This idea is a core of some algorithms, e.g. QR decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unitary invariance of $\\|\\cdot\\|_2$ and $\\|\\cdot\\|_F$ norms\n",
    "\n",
    "- For vector 2-norm we have already seen that $\\Vert U z \\Vert_2 = \\Vert z \\Vert_2$ for any unitary $U$.\n",
    "\n",
    "- One can show that unitary matrices also do not change matrix norms $\\|\\cdot\\|_2$ and $\\|\\cdot\\|_F$, i.e. for any square $A$ and unitary $U$,$V$: \n",
    "\n",
    "$$ \\| UAV\\|_2 = \\| A \\|_2 \\qquad \\| UAV\\|_F = \\| A \\|_F.$$\n",
    "\n",
    "- For $\\|\\cdot\\|_2$ it follows from the definition of an operator norm and the fact that vector 2-norm is unitary invariant.\n",
    "\n",
    "- For $\\|\\cdot\\|_F$ it follows from $\\|A\\|_F^2 = \\mathrm{trace}(A^*A)$ and the fact that $\\mathrm{trace}(BC) = \\mathrm{trace}(CB)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples of unitary matrices\n",
    "- There are two important classes of unitary matrices, using composition of which we can construct any unitary matrix:\n",
    "\n",
    "    1. Householder matrices\n",
    "    2. Givens (Jacobi) matrices\n",
    "\n",
    "- Other important examples are\n",
    "    * **Permutation matrix** $P$ whose rows (columns) are permutation of rows (columns) of the identity matrix.\n",
    "    * **Fourier matrix** $F_n = \\frac{1}{\\sqrt{n}} \\left\\{ e^{-i\\frac{2\\pi kl}{n}}\\right\\}_{k,l=0}^{n-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Householder matrices\n",
    "\n",
    "- Householder matrix is the matrix of the form \n",
    "\n",
    "$$H \\equiv H(v) = I - 2 vv^*,$$\n",
    "\n",
    "where $v$ is an $n \\times 1$ column and $v^* v = 1$. \n",
    "- Can you show that $H$ is unitary and Hermitian ($H^* = H$)?  \n",
    "- It is also a reflection:\n",
    "\n",
    "$$ Hx = x - 2(v^* x) v$$\n",
    "\n",
    "<img src=\"householder.jpeg\" width=500>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important property of Householder reflection\n",
    "\n",
    "- A nice property of Householder transformation is that it can zero all elements of a vector except for the first one:\n",
    "\n",
    "$$ H \\begin{bmatrix} \\times \\\\ \\times \\\\ \\times \\\\ \\times  \\end{bmatrix} =  \\begin{bmatrix} \\times \\\\ 0 \\\\ 0 \\\\ 0  \\end{bmatrix}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Proof (for real case).* Let $e_1 = (1,0,\\dots, 0)^T$, then we want to find $v$ such that\n",
    "\n",
    "$$ H x = x - 2(v^* x) v = \\alpha e_1, $$\n",
    "\n",
    "where $\\alpha$ is an unknown constant. Since $\\|\\cdot\\|_2$ is unitary invariant we get\n",
    "\n",
    "$$\\|x\\|_2 = \\|Hx\\|_2 = \\|\\alpha e_1\\|_2 = |\\alpha|.$$\n",
    "\n",
    "and $$\\alpha = \\pm \\|x\\|_2$$\n",
    "\n",
    "Also, we can express $v$ from $x - 2(v^* x) v = \\alpha e_1$:\n",
    "\n",
    "$$v = \\dfrac{x-\\alpha e_1}{2 v^* x}$$\n",
    "\n",
    "Multiplying the latter expression by $x^*$ we get\n",
    "\n",
    "$$x^* x - 2 (v^* x) x^* v = \\alpha x_1; $$\n",
    "\n",
    "or \n",
    "\n",
    "$$ \\|x\\|_2^2 - 2 (v^* x)^2 = \\alpha x_1. $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$ (v^* x)^2 = \\frac{\\|x\\|_2^2 - \\alpha x_1}{2}. $$\n",
    "\n",
    "So, $v$ exists and equals\n",
    "\n",
    "$$ v = \\dfrac{x \\pm \\|x\\|_2 e_1}{2v^* x} = \\dfrac{x \\pm \\|x\\|_2 e_1}{\\pm\\sqrt{2(\\|x\\|_2^2 \\mp \\|x\\|_2 x_1)}}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Householder algorithm for QR decomposition\n",
    "\n",
    "Using the obtained property we can make arbitrary matrix $A$ lower triangular:\n",
    "\n",
    "$$\n",
    "H_2 H_1 A = \\begin{bmatrix} \\times & \\times & \\times & \\times \\\\ 0 & \\times & \\times & \\times  \\\\  0 & 0 & \\boldsymbol{\\times} & \\times\\\\ 0 &0 & \\boldsymbol{\\times} & \\times  \\\\ 0 &0 & \\boldsymbol{\\times} & \\times \\end{bmatrix} $$\n",
    "\n",
    "then finding $H_3=\\begin{bmatrix}I_2 & \\\\ & {\\widetilde H}_3 \\end{bmatrix}$ such that\n",
    "\n",
    "$$ {\\widetilde H}_3 \\begin{bmatrix} \\boldsymbol{\\times}\\\\ \\boldsymbol{\\times} \\\\ \\boldsymbol{\\times}  \\end{bmatrix} = \\begin{bmatrix} \\times \\\\ 0 \\\\ 0  \\end{bmatrix}. $$\n",
    "\n",
    "we get\n",
    "\n",
    "$$ H_3 H_2 H_1 A =  \\begin{bmatrix} \\times & \\times & \\times & \\times \\\\  0 & \\times & \\times & \\times  \\\\  0 & 0 & {\\times} & \\times\\\\  0 &0 & 0 & \\times  \\\\  0 &0 & 0 & \\times  \\end{bmatrix} $$\n",
    "\n",
    "Finding $H_4$ by analogy we arrive at upper-triangular matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since product and inverse of unitary matrices is a unitary matrix we get:\n",
    "\n",
    "**Corollary:** (QR decomposition) Every $A\\in \\mathbb{C}^{n\\times m}$ can be represented as\n",
    "\n",
    "$$ A = QR, $$\n",
    "\n",
    "where $Q$ is unitary and $R$ is upper triangular. \n",
    "\n",
    "See [poster](../../decompositions.pdf), what are the sizes of $Q$ and $R$ for $n>m$ and $n<m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Givens (Jacobi) matrix\n",
    "\n",
    "- A Givens matrix is a matrix  \n",
    "\n",
    "$$ G = \\begin{bmatrix} \\cos \\alpha & -\\sin \\alpha \\\\ \\sin \\alpha & \\cos \\alpha \\end{bmatrix},$$\n",
    "\n",
    "which is a rotation. \n",
    "\n",
    "- For a general case, we select two $(i, j)$ planes and rotate vector $x$  \n",
    "\n",
    "$$ x' = G x, $$\n",
    "\n",
    "only in the $i$-th and $j$-th positions:\n",
    "\n",
    "$$ x'_i =  x_i\\cos \\alpha - x_j\\sin \\alpha , \\quad x'_j = x_i \\sin \\alpha  +  x_j\\cos\\alpha, $$\n",
    "\n",
    "with all other $x_i$ remain unchanged.\n",
    "- Therefore, we can make elements in the $j$-th  position zero by choosing $\\alpha$ such that\n",
    "\n",
    "$$ \\cos \\alpha = \\frac{x_i}{\\sqrt{x_i^2 + x_j^2}}, \\quad \\sin \\alpha = -\\frac{x_j}{\\sqrt{x_i^2 + x_j^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhU9dn/8ffNrqg1yCoiQkEl7DKCoKhFQAQRrBRDXVBRSuuKlQoPjxtulEcFt6pRcKEWF3qpqHghqysoUQmEUCRiW1OooCguIOv9+2MO/MYwSU6YmUwSPq/rmmvO+X6/55w7hyGfnDNnzpi7IyIiEka1dBcgIiKVh0JDRERCU2iIiEhoCg0REQlNoSEiIqEpNEREJLSkhIaZTTOzDWaWV0y/mdkDZlZgZsvN7ISYvuFmtiZ4DE9GPSIikhrJOtJ4CuhXQv9ZQOvgMRJ4BMDM6gG3AN2ArsAtZpaRpJpERCTJkhIa7v42sKmEIYOAZzxqCXC4mTUBzgTmuvsmd/8GmEvJ4SMiImlUo5y20xT4Ima+MGgrrn0fZjaS6FEKdevW7XL88cenplIRkSrqo48++srdGySyjvIKDYvT5iW079vong1kA0QiEc/JyUledSIiBwAz+1ei6yivq6cKgWYx80cB60poFxGRCqi8QmMWcHFwFdVJwGZ3Xw/MAfqaWUbwBnjfoE1ERCqgpJyeMrMZwOlAfTMrJHpFVE0Ad38UmA30BwqALcClQd8mM7sdWBqsaoK7l/SGuoiIpFFSQsPdh5XS78CVxfRNA6Ylow4REUktfSJcRERCU2iIiEhoCg0REQlNoSEiIqEpNEREJDSFhoiIhKbQEBGR0BQaIiISmkJDRERCU2iIiEhoCg0REQlNoSEiIqEpNEREJDSFhoiIhKbQEBGR0BQaIiISmkJDRERCU2iIiEhoSQkNM+tnZqvNrMDMxsbpn2xmy4LHp2b2bUzfrpi+WcmoR0REUiPh7wg3s+rAw0AfoBBYamaz3D1/zxh3Hx0z/mqgc8wqtrp7p0TrEBGR1EvGkUZXoMDd17r7duA5YFAJ44cBM5KwXRERKWfJCI2mwBcx84VB2z7MrDnQAlgQ01zHzHLMbImZDU5CPSIikiIJn54CLE6bFzM2C5jp7rti2o5293Vm1hJYYGYr3P2zfTZiNhIYCXD00UcnWrOIiOyHZBxpFALNYuaPAtYVMzaLIqem3H1d8LwWWMTP3++IHZft7hF3jzRo0CDRmkVEZD8kIzSWAq3NrIWZ1SIaDPtcBWVmxwEZwOKYtgwzqx1M1wdOBvKLLisiIhVDwqen3H2nmV0FzAGqA9PcfaWZTQBy3H1PgAwDnnP32FNXbYDHzGw30QCbGHvVlYiIVCz289/hlUMkEvGcnJx0l7Hfdu3axZQpU2jRogV9+vTh0EMPTXdJInIAMLOP3D2SyDqS8Ua4lFH16tU599xz6datG5s3b+bUU09lwIABDBgwgGOPPTbd5YmIFEtHGmn03nvv0atXL7Zv3763rVWrVgwYMID+/ftz2mmnUbt27TRWKCJVSTKONBQaafbss89y4YUXxu2rW7cuvXv3ZsCAAZx33nnUq1evnKsTkaokGaGhGxam2QUXXMDNN98ct+/HH39k0aJFbN26Ve97iEiFoNCoAG699VaysrLi9o0dO5arr76amjVrlnNVIiL7UmhUAGbGk08+yUknnbRP37hx4+jbty+ff/55GioTEfk5hUYFUadOHV5++WWaN28OQMeOHWncuDEA8+bNo127dtx///3s2rWrpNWIiKSUQqMCadSoEa+99hqHHnoo/fv3Jz8/n8suuwyALVu2cN1119GzZ0/y8/X5RxFJD4VGBdOuXTteeOEFWrRoQUZGBlOnTmXu3Lkcc8wxACxevJjOnTtzxx13sGPHjvQWKyIHHF1yW0Ht2LHjZ29+//DDD9x0003cf//97Pk369ChA9OmTaNLly7pKlNEKhFdcluFFb1a6pBDDmHy5Mm89957tGnTBoDly5fTtWtXbrzxRrZu3ZqOMkXkAKPQqGS6d+/OJ598wk033USNGjXYvXs3kyZNokOHDrz11lvpLk9EqjiFRiVUu3ZtJkyYQE5Ozt5TUwUFBZx++un8/ve/57vvvktzhSJSVSk0KrGOHTuyZMkSJk2aRJ06dQB49NFHadu2LbNnz05zdSJSFSk0KrkaNWowZswYcnNzOfXUUwEoLCxkwIABXHjhhXz11VdprlBEqhKFRhVx7LHHsnDhQh555JG996l69tlnyczM5Pnnn6cyXiUnIhWPQqMKqVatGqNGjWLlypX0798fgI0bN5KVlcXgwYP5z3/+k+YKRaSyU2hUQc2aNeO1117jr3/9K0cccQQAs2bNIjMzk8cff1xHHSKy3xQaVZSZccEFF5Cfn7/3DrrfffcdI0eO5IwzzuCzzz5Lc4UiUhklJTTMrJ+ZrTazAjMbG6f/EjPbaGbLgsflMX3DzWxN8BiejHrk/2vYsCEzZszglVde4cgjjwRg4cKFtG/fnvvuu083QBSRMkk4NMysOvAwcBaQCQwzs8w4Q593907B44lg2XrALUA3oCtwi5llJFqT7Oucc85h5cqVXHHFFQBs3bqVP/7xj/To0YO8vLw0VycilUUyjjS6AgXuvtbdtwPPAYNCLnsmMNfdN7n7N8BcoF8SapI4Dj/8cLKzs5k/fz4tW7YE4MMPP+SEE07gtttu+9l3lYuIxJOM0GgKfBEzXxi0FXWemS03s5lm1qyMy2JmI80sx8xyNm7cmISyD1y9evVixYoVXH/99VSrVo0dO3Zw66230qVLFz788MN0lyciFVgyQsPitBW9POdV4Bh37wDMA54uw7LRRvdsd4+4e6RBgwb7XaxEHXzwwdx77728//77tG3bFoC8vDy6d+/ODTfcwJYtW9JcoYhURMkIjUKgWcz8UcC62AHu/rW7bwtmHwe6hF1WUqtbt258/PHH3HLLLdSsWZPdu3dz77330r59exYuXJju8kSkgklGaCwFWptZCzOrBWQBs2IHmFmTmNlzgFXB9Bygr5llBG+A9w3apBzVqlWLW2+9lY8++ogTTzwRgLVr19KrVy9+97vfsXnz5jRXKCIVRcKh4e47gauI/rJfBbzg7ivNbIKZnRMMu8bMVppZLnANcEmw7CbgdqLBsxSYELRJGrRv357Fixdzzz33cNBBBwGQnZ1NZmYmr776apqrE5GKQN/cJ3EVFBRwxRVXsGjRor1tw4YN4/7770fvKYlUTvrmPkmZVq1asWDBArKzsznssMMAmDFjBm3atOFvf/ubbkUicoBSaEixzIwrrriC/Px8Bg4cCMDXX3/NBRdcwMCBA/niiy9KWYOIVDUKDSlV06ZNeeWVV5gxYwb169cH4PXXX6dt27Y89thj7N69O80Vikh5UWhIKGZGVlYWq1at4re//S0A33//PaNGjaJXr16sWbMmzRWKSHlQaEiZ1K9fn2effZZXX32Vpk2jH95/66236NChA/fccw87d+5Mc4UikkoKDdkvZ599Nvn5+YwaNQqAn376iTFjxtC9e3eWL1+e5upEJFUUGrLfDjvsMB555BEWLVpEq1atAMjJyaFLly7cfPPNbNu2rZQ1iEhlo9CQhJ122mnk5uYyZswYqlWrxs6dO7n99ts54YQTWLJkSbrLE5EkUmhIUhx88MFMmjSJDz74gPbt2wOQn59Pjx49GD16ND/++GOaKxSRZFBoSFJFIhFycnKYMGECNWvWxN2ZMmUK7du3Z/78+ekuT0QSpNCQpKtVqxY33XQTn3zyCSeddBIAn3/+Ob179+byyy/n22+/TXOFIrK/FBqSMm3btuXdd99lypQpHHzwwQBMnTqVzMxMXn755TRXJyL7Q6EhKVW9enWuvfZaVqxYwRlnnAHA+vXrOffccxk6dChffvllmisUkbJQaEi5aNmyJXPnzmXq1Kn84he/AODFF18kMzOT6dOn6waIIpWEQkPKjZlx2WWXkZ+fz6BBgwDYtGkTF198MQMGDODf//53misUkdIoNKTcHXnkkbz00ku88MILNGzYEIA33niDtm3b8pe//EU3QBSpwBQakhZmxm9+8xvy8/O56KKLAPjhhx+48sorOf3001m9enWaKxSReBQaklZHHHEEzzzzDLNnz6ZZs2YAvPPOO3Ts2JGJEyfqBogiFUxSQsPM+pnZajMrMLOxcfqvN7N8M1tuZvPNrHlM3y4zWxY8ZiWjHql8zjrrLFauXMmVV14JwLZt2xg3bhzdunVj2bJlaa5ORPZIODTMrDrwMHAWkAkMM7PMIsM+ASLu3gGYCUyK6dvq7p2CxzmJ1iOV16GHHspDDz3E22+/TevWrQH4+OOPiUQijB8/np9++inNFYpIMo40ugIF7r7W3bcDzwGDYge4+0J33xLMLgGOSsJ2pYrq2bMnubm5jB07lurVq7Nr1y7uuusuOnfuzPvvv5/u8kQOaMkIjaZA7JdFFwZtxRkBvBEzX8fMcsxsiZkNLm4hMxsZjMvZuHFjYhVLhXfQQQdx991388EHH9CxY0cA/vGPf3DKKadwzTXX8MMPP6S5QpEDUzJCw+K0xf2klpldCESA/4tpPtrdI8BvgSlm9st4y7p7trtH3D3SoEGDRGuWSqJLly4sXbqUO++8k1q1auHuPPjgg7Rr144333wz3eWJHHCSERqFQLOY+aOAdUUHmVlvYDxwjrvv/XYed18XPK8FFgGdk1CTVCE1a9bkf/7nf8jNzaVHjx4A/Otf/+LMM8/k0ksvZdOmTWmuUOTAkYzQWAq0NrMWZlYLyAJ+dhWUmXUGHiMaGBti2jPMrHYwXR84GchPQk1SBR1//PG88847PPDAA9StWxeAp556iszMTP7+97+nuTqRA0PCoeHuO4GrgDnAKuAFd19pZhPMbM/VUP8HHAK8WOTS2jZAjpnlAguBie6u0JBiVatWjauvvpq8vDz69OkDwJdffsmQIUMYMmQI//3vf9NcoUjVZpXxRnGRSMRzcnLSXYakmbvz9NNPM3r06L3f0ZGRkcF9993H8OHDMYv3dpvIgcvMPgreQ95v+kS4VFpmxiWXXMKqVas477zzAPjmm2+49NJL6devH//85z/TW6BIFaTQkEqvcePGzJw5k5kzZ9KoUSMA3nzzTdq1a8eDDz6oGyCKJJFCQ6qM8847j/z8fC655BIAfvzxR6655hp69uzJqlWr0lucSBWh0JAqpV69ejz55JPMmTOH5s2jtzh7//336dSpE3fddRc7duxIc4UilZtCQ6qkvn37kpeXx9VXX42ZsX37dsaPH0/Xrl35+OOP012eSKWl0JAq65BDDuGBBx7gnXfe4bjjjgNg2bJldO3alXHjxrF169Y0VyhS+Sg0pMo7+eSTWbZsGePHj997A8SJEyfSqVMn3n333XSXJ1KpKDTkgFCnTh3uuOMOcnJy6Nw5eqeaTz/9lJ49e3LVVVfx/fffp7lCkcpBoSEHlE6dOvHhhx8yceJEateuDcDDDz9M27ZteeONN0pZWkQUGnLAqVGjBjfeeCO5ubmccsopAHzxxRf079+fiy++mK+//jrNFYpUXAoNOWAdd9xxvPXWWzz88MMccsghAEyfPp3MzExefPFFKuMtdkRSTaEhB7Rq1arxhz/8gby8PPr16wfAhg0bGDp0KL/+9a9Zv359misUqVgUGiJA8+bNmT17Ns888wz16tUD4OWXX6ZNmzZMmzZNRx0iAYWGSMDMuOiii8jPz2fo0KEAbN68mREjRtCnTx/Wrl2b5gpF0k+hIVJEo0aNeP7553nppZdo3LgxAPPnz6d9+/ZMmTKFXbt2pblCkfRRaIgUY/DgweTn5zNixAgAtmzZwujRoznllFPIz9d3hcmBSaEhUoKMjAyeeOIJ5s6dyzHHHAPAkiVL6Ny5M7fffjvbt29Pb4Ei5UyhIRJC7969ycvL47rrrtt7A8Sbb76ZE088EX2LpKTD448/zvz588v9D5ekhIaZ9TOz1WZWYGZj4/TXNrPng/4PzOyYmL5xQftqMzszGfWIpELdunWZPHky7733HpmZmQAsX76cbt268ac//YktW7akuUI5kBx22GH07t2bBg0acP755zN9+vRy+WBqwt8RbmbVgU+BPkAhsBQY5u75MWP+AHRw91FmlgWc6+7nm1kmMAPoChwJzAOOdfcS32nUd4RLum3bto0777yTu+++m507dwLQqlUrbrvtNtq3b5/m6uRAsGvXLvr37/+zzxJVq1aNHj16MHDgQAYOHMjxxx+Pme3tT8Z3hOPuCT2A7sCcmPlxwLgiY+YA3YPpGsBXgBUdGzuupEeXLl1cpCLIzc31Ll26OOCAN2zYcO+0Hnqk+9GyZUu/9tprfd68eb5t2zYHcjzB3/nJOD3VFPgiZr4waIs7xt13ApuBI0IuC4CZjTSzHDPL2bhxYxLKFklchw4dWLJkCZMmTeKXv/zl3m8LFKkICgsLWb16NatXr07aqasaSViHxWnzkGPCLBttdM8GsiF6eqosBYqkUo0aNRgzZgzXXXcdb7/9tm54KOXC3Rk9evQ+t7pp2LAhAwYMYODAgfTp02fvfdWSJRmhUQg0i5k/ClhXzJhCM6sB/ALYFHJZkUqhZs2anHHGGekuQw4QCxYs2BsYHTp02Ps+xoknnki1aqm7MDYZobEUaG1mLYD/AFnAb4uMmQUMBxYDQ4AF7u5mNgv4m5ndR/SN8NbAh0moSUSkSlu8eDEPPfQQZ599drmeFk04NNx9p5ldRfRN7OrANHdfaWYTiL7pMguYCkw3swKiRxhZwbIrzewFIB/YCVzppVw5JSIiMH78+LRsN+FLbtNBl9yKiJRdMi651SfCRUQkNIWGiIiEptAQEZHQFBoiIhKaQkNEREJTaIiISGgKDRERCU2hISIioSk0REQkNIWGiIiEptAQEZHQFBoiIhKaQkNEREJTaIiISGgKDRERCU2hISIioSk0REQkNIWGiIiEllBomFk9M5trZmuC54w4YzqZ2WIzW2lmy83s/Ji+p8zsczNbFjw6JVKPiIikVqJHGmOB+e7eGpgfzBe1BbjY3dsC/YApZnZ4TP8Yd+8UPJYlWI+IiKRQoqExCHg6mH4aGFx0gLt/6u5rgul1wAagQYLbFRGRNEg0NBq5+3qA4LlhSYPNrCtQC/gspvnO4LTVZDOrXcKyI80sx8xyNm7cmGDZIiKyP0oNDTObZ2Z5cR6DyrIhM2sCTAcudffdQfM44HjgRKAecGNxy7t7trtH3D3SoIEOVERE0qFGaQPcvXdxfWb2pZk1cff1QShsKGbcYcDrwP+6+5KYda8PJreZ2ZPADWWqXkREylWip6dmAcOD6eHAK0UHmFkt4CXgGXd/sUhfk+DZiL4fkpdgPSIikkKJhsZEoI+ZrQH6BPOYWcTMngjGDAVOBS6Jc2nts2a2AlgB1AfuSLAeERFJIXP3dNdQZpFIxHNyctJdhohIpWJmH7l7JJF16BPhIiISmkJDRERCU2iIiEhoCg0REQlNoSEiIqEpNEREJDSFhoiIhKbQEBGR0BQaIiISmkJDRERCU2iIiEhoCg0REQlNoSEiIqEpNEREJDSFhoiIhKbQEBGR0BQaIiISmkJDRERCSyg0zKyemc01szXBc0Yx43bFfD/4rJj2Fmb2QbD882ZWK5F6REQktRI90hgLzHf31sD8YD6ere7eKXicE9P+Z2BysPw3wIgE6xERkRRKNDQGAU8H008Dg8MuaGYG9AJm7s/yIiJS/hINjUbuvh4geG5YzLg6ZpZjZkvMbE8wHAF86+47g/lCoGlxGzKzkcE6cjZu3Jhg2SIisj9qlDbAzOYBjeN0jS/Ddo5293Vm1hJYYGYrgO/ijPPiVuDu2UA2QCQSKXaciIikTqmh4e69i+szsy/NrIm7rzezJsCGYtaxLnhea2aLgM7A34HDzaxGcLRxFLBuP34GEREpJ4menpoFDA+mhwOvFB1gZhlmVjuYrg+cDOS7uwMLgSElLS8iIhVHoqExEehjZmuAPsE8ZhYxsyeCMW2AHDPLJRoSE909P+i7EbjezAqIvscxNcF6REQkhSz6B3/lEolEPCcnJ91liIhUKmb2kbtHElmHPhEuIiKhKTRERCQ0hYaIiISm0BARkdAUGiIiEppCQ0REQlNoiIhIaAoNEREJTaEhIiKhKTRERCQ0hYaIiISm0BARkdAUGiIiEppCQ0REQlNoiIhIaAoNEREJTaEhIiKhKTRERCS0hELDzOqZ2VwzWxM8Z8QZ8yszWxbz+MnMBgd9T5nZ5zF9nRKpR0REUivRI42xwHx3bw3MD+Z/xt0Xunsnd+8E9AK2AG/GDBmzp9/dlyVYj4iIpFCioTEIeDqYfhoYXMr4IcAb7r4lwe2KiEgaJBoajdx9PUDw3LCU8VnAjCJtd5rZcjObbGa1E6xHRERSqEZpA8xsHtA4Ttf4smzIzJoA7YE5Mc3jgP8CtYBs4EZgQjHLjwRGAhx99NFl2bSIiCRJqaHh7r2L6zOzL82sibuvD0JhQwmrGgq85O47Yta9PpjcZmZPAjeUUEc20WAhEol4aXWLiEjyJXp6ahYwPJgeDrxSwthhFDk1FQQNZmZE3w/JS7AeERFJoURDYyLQx8zWAH2CecwsYmZP7BlkZscAzYC3iiz/rJmtAFYA9YE7EqxHRERSqNTTUyVx96+BM+K05wCXx8z/E2gaZ1yvRLYvIiLlS58IFxGR0BQaIiISmkJDRERCU2iIiEhoCg0REQlNoSEiIqEpNEREJDSFhoiIhKbQEBGR0BQaIiISmkJDRERCU2iIiEhoCg0REQlNoSEiIqEpNEREJDSFhoiIhKbQEBGR0BQaIiISmkJDRERCSyg0zOw3ZrbSzHabWaSEcf3MbLWZFZjZ2Jj2Fmb2gZmtMbPnzaxWIvWIiEhqJXqkkQf8Gni7uAFmVh14GDgLyASGmVlm0P1nYLK7twa+AUYkWI+IiKRQQqHh7qvcfXUpw7oCBe6+1t23A88Bg8zMgF7AzGDc08DgROoREZHUqlEO22gKfBEzXwh0A44AvnX3nTHtTYtbiZmNBEYGs9vMLC8FtSZbfeCrdBcRQmWoszLUCKoz2VRnch2X6ApKDQ0zmwc0jtM13t1fCbENi9PmJbTH5e7ZQHZQU467F/seSkWhOpOnMtQIqjPZVGdymVlOousoNTTcvXeC2ygEmsXMHwWsI5rKh5tZjeBoY0+7iIhUUOVxye1SoHVwpVQtIAuY5e4OLASGBOOGA2GOXEREJE0SveT2XDMrBLoDr5vZnKD9SDObDRAcRVwFzAFWAS+4+8pgFTcC15tZAdH3OKaG3HR2InWXI9WZPJWhRlCdyaY6kyvhOi36B7+IiEjp9IlwEREJTaEhIiKhVdjQqAy3KDGzemY2N9jGXDPLiDPmV2a2LObxk5kNDvqeMrPPY/o6JbvGsHUG43bF1DIrpr1cbvcScn92MrPFwWtjuZmdH9OX0v1Z3Gstpr92sH8Kgv11TEzfuKB9tZmdmcy69qPO680sP9h/882seUxf3NdAGmq8xMw2xtRyeUzf8OA1ssbMhqeqxpB1To6p8VMz+zamr1z2ZbCtaWa2wYr5/JpFPRD8HMvN7ISYvrLtT3evkA+gDdEPoiwCIsWMqQ58BrQEagG5QGbQ9wKQFUw/Cvw+BTVOAsYG02OBP5cyvh6wCTg4mH8KGFIO+zJUncAPxbSnfF+GrRM4FmgdTB8JrAcOT/X+LOm1FjPmD8CjwXQW8HwwnRmMrw20CNZTPY11/irmNfj7PXWW9BpIQ42XAA/FWbYesDZ4zgimM9JVZ5HxVwPTynNfxmzrVOAEIK+Y/v7AG0Q/H3cS8MH+7s8Ke6ThleMWJYOCdYfdxhDgDXffkoJaSlLWOvcqx30JIep090/dfU0wvQ7YADRIUT2x4r7WioyJrX8mcEaw/wYBz7n7Nnf/HCgI1peWOt19YcxrcAnRz0iVpzD7sjhnAnPdfZO7fwPMBfpVkDqHATNSVEuJ3P1ton+QFmcQ8IxHLSH6Gbkm7Mf+rLChEVK8W5Q0pYy3KElAI3dfDxA8NyxlfBb7vqjuDA4XJ5tZ7RTUCOHrrGNmOWa2ZM8pNMpvX5alTgDMrCvRvwA/i2lO1f4s7rUWd0ywvzYT3X9hli3POmONIPoX6B7xXgPJFrbG84J/y5lmtucDwhVyXwan+FoAC2Kay2NfhlXcz1Lm/Vke954qllWQW5SUuIESaizjepoA7Yl+XmWPccB/if7iyyb6uZUJaazzaHdfZ2YtgQVmtgL4Ls64/b5OO8n7czow3N13B81J25/xNhmnreh+SPnrMYTQ2zKzC4EIcFpM8z6vAXf/LN7yKa7xVWCGu28zs1FEj+B6hVw2WcqyrSxgprvvimkrj30ZVtJem2kNDa8EtygpqUYz+9LMmrj7+uCX2IYSVjUUeMndd8Sse30wuc3MngRu2J8ak1VncLoHd19rZouAzsDfSeLtXpJRp5kdBrwO/G9wqL1n3Unbn3EU91qLN6bQzGoAvyB6yiDMsuVZJ2bWm2hQn+bu2/a0F/MaSPYvulJrdPevY2YfJ/o1CnuWPb3IsouSXN8eZfl3ywKujG0op30ZVnE/S5n3Z2U/PZXuW5TMCtYdZhv7nO8MfjHued9gMNHvJ0mFUus0s4w9p3PMrD5wMpBfjvsybJ21gJeInp99sUhfKvdn3NdaCfUPARYE+28WkGXRq6taAK2BD5NYW5nqNLPOwGPAOe6+IaY97msgTTU2iZk9h+jdJCB6pN43qDUD6MvPj97Ltc6g1uOIvom8OKatvPZlWLOAi4OrqE4CNgd/ZJV9f5bXu/tlfQDnEk3BbcCXwJyg/Uhgdsy4/sCnRBN8fEx7S6L/MQuAF4HaKajxCGA+sCZ4rhe0R4AnYsYdA/wHqFZk+QXACqK/3P4KHJKifVlqnUCPoJbc4HlEee7LMtR5IbADWBbz6FQe+zPea43o6a9zguk6wf4pCPZXy5hlxwfLrQbOSvH/ndLqnBf8n9qz/2aV9hpIQ413AyuDWhYCx8cse1mwjwuAS9O5L4P5W4GJRZYrt30ZbG8G0SsJd7g4hl8AAABOSURBVBD9vTkCGAWMCvqN6JfhfRbUE4lZtkz7U7cRERGR0Cr76SkRESlHCg0REQlNoSEiIqEpNEREJDSFhoiIhKbQEBGR0BQaIiIS2v8DrawFhRvVvXcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "alpha = -3*jnp.pi / 4\n",
    "G = jnp.array([\n",
    "    [jnp.cos(alpha), -jnp.sin(alpha)],\n",
    "    [jnp.sin(alpha), jnp.cos(alpha)]\n",
    "])\n",
    "x = jnp.array([-1./jnp.sqrt(2), 1./jnp.sqrt(2)])\n",
    "y = G @ x\n",
    "\n",
    "plt.quiver([0, 0], [0, 0], [x[0], y[0]], [x[1], y[1]], angles='xy', scale_units='xy', scale=1)\n",
    "plt.xlim(-1., 1.)\n",
    "plt.ylim(-1., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QR via Givens rotations\n",
    "\n",
    "Similarly we can make matrix upper-triangular using Givens rotations:\n",
    "\n",
    "$$\\begin{bmatrix} \\times & \\times & \\times \\\\ \\bf{*} & \\times & \\times \\\\ \\bf{*} & \\times & \\times \\end{bmatrix} \\to \\begin{bmatrix} * & \\times & \\times \\\\ * & \\times & \\times \\\\ 0 & \\times & \\times \\end{bmatrix} \\to \\begin{bmatrix} \\times & \\times & \\times \\\\ 0 & * & \\times \\\\ 0 & * & \\times \\end{bmatrix} \\to \\begin{bmatrix} \\times & \\times & \\times \\\\ 0 & \\times & \\times \\\\ 0 & 0 & \\times \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Givens vs. Householder transformations\n",
    "\n",
    "- Householder reflections are useful for dense matrices (complexity is $\\approx$ twice smaller than for Jacobi) and we need to zero large number of elements.\n",
    "- Givens rotations are more suitable for sparse matrice or parallel machines as they act locally on elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "SVD will be considered later in more details.\n",
    "\n",
    "**Theorem.** Any matrix $A\\in \\mathbb{C}^{n\\times m}$ can be written as a product of three matrices:  \n",
    "\n",
    "$$ A = U \\Sigma V^*, $$\n",
    "\n",
    "where \n",
    "- $U$ is an $n \\times n$ unitary matrix\n",
    "- $V$ is an $m \\times m$ unitary matrix\n",
    "- $\\Sigma$ is a diagonal matrix with non-negative elements $\\sigma_1 \\geq  \\ldots, \\geq \\sigma_{\\min (m,n)}$ on the diagonal.\n",
    "\n",
    "Moreover, if $\\text{rank}(A) = r$, then $\\sigma_{r+1} = \\dots = \\sigma_{\\min (m,n)} = 0$.\n",
    "\n",
    "See [poster](../../decompositions.pdf) for the visualization.\n",
    "\n",
    "- **Important note:** if one truncates (replace by $0$) all singular values except for $r$ first, then the resulting matrix yields best rank-$r$ approximation both in $\\|\\cdot\\|_2$ and $\\|\\cdot\\|_F$. \n",
    "- This is called Eckart-Young theorem and will be proved later in our course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "\n",
    "- Most important matrix norms: Frobenius and spectral\n",
    "\n",
    "- Unitary matrices preserve these norms\n",
    "\n",
    "- There are two \"basic\" classes of unitary matrices: Householder and Givens matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
